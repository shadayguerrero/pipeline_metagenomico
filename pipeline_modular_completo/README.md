# Pipeline Metagen√≥mico Modular - Versi√≥n 1.0

## üì¶ Contenido del Paquete

Este paquete contiene el pipeline metagen√≥mico completo con 10 m√≥dulos funcionales para el an√°lisis integral de datos metagen√≥micos.

### Archivos Principales

```
pipeline_modular_completo/
‚îÇ
‚îú‚îÄ‚îÄ SCRIPTS PRINCIPALES
‚îÇ   ‚îú‚îÄ‚îÄ metagenomics_pipeline.sh              # Pipeline principal (men√∫ interactivo)
‚îÇ   ‚îî‚îÄ‚îÄ setup_micromamba.sh                   # Configuraci√≥n de micromamba
‚îÇ
‚îú‚îÄ‚îÄ SCRIPTS POR M√ìDULO (opcionales, el pipeline principal los incluye)
‚îÇ   ‚îú‚îÄ‚îÄ run_trimgalore.sh                     # M√≥dulo 1: QC & Trimming
‚îÇ   ‚îú‚îÄ‚îÄ run_host_removal.sh                   # M√≥dulo 2: Host Removal
‚îÇ   ‚îú‚îÄ‚îÄ run_megahit.sh                        # M√≥dulo 3: Assembly
‚îÇ   ‚îú‚îÄ‚îÄ run_binning_fixed.sh                  # M√≥dulo 4: Binning
‚îÇ   ‚îú‚îÄ‚îÄ run_kraken2.sh                        # M√≥dulo 5: Taxonom√≠a Reads
‚îÇ   ‚îú‚îÄ‚îÄ run_gtdbtk.sh                         # M√≥dulo 6: Taxonom√≠a Bins
‚îÇ   ‚îî‚îÄ‚îÄ run_prokka.sh                         # M√≥dulo 7: Anotaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ SCRIPTS DE PROCESAMIENTO KRAKEN2
‚îÇ   ‚îú‚îÄ‚îÄ combinar_kraken_simple_a_biom.py      # Conversi√≥n 1 DB ‚Üí BIOM
‚îÇ   ‚îú‚îÄ‚îÄ combinar_kraken_2bases_a_biom.py      # Conversi√≥n 2 DBs ‚Üí BIOM
‚îÇ   ‚îî‚îÄ‚îÄ combinar_kraken_3bases_a_biom_v4.py   # Conversi√≥n 3 DBs ‚Üí BIOM
‚îÇ
‚îú‚îÄ‚îÄ SCRIPTS DE AN√ÅLISIS
‚îÇ   ‚îú‚îÄ‚îÄ analisis_sin_metadatos.py             # An√°lisis sin metadatos
‚îÇ   ‚îî‚îÄ‚îÄ analisis_metagenomico_completo.py     # An√°lisis completo
‚îÇ
‚îú‚îÄ‚îÄ ARCHIVOS DE AMBIENTES (YAML)
‚îÇ   ‚îú‚îÄ‚îÄ 01_trimgalore.yaml                    # Ambiente m√≥dulo 1
‚îÇ   ‚îú‚îÄ‚îÄ 02_host_removal.yaml                  # Ambiente m√≥dulo 2
‚îÇ   ‚îú‚îÄ‚îÄ 03_megahit.yaml                       # Ambiente m√≥dulo 3
‚îÇ   ‚îú‚îÄ‚îÄ 04_binning.yaml                       # Ambiente m√≥dulo 4
‚îÇ   ‚îú‚îÄ‚îÄ 05_kraken2.yaml                       # Ambiente m√≥dulo 5
‚îÇ   ‚îú‚îÄ‚îÄ 06_gtdbtk.yaml                        # Ambiente m√≥dulo 6
‚îÇ   ‚îú‚îÄ‚îÄ 07_prokka.yaml                        # Ambiente m√≥dulo 7
‚îÇ   ‚îú‚îÄ‚îÄ 08_rgi.yaml                           # Ambiente m√≥dulo 8
‚îÇ   ‚îú‚îÄ‚îÄ 09_antismash.yaml                     # Ambiente m√≥dulo 9
‚îÇ   ‚îú‚îÄ‚îÄ 10_analysis.yaml                      # Ambiente m√≥dulo 10
‚îÇ   ‚îú‚îÄ‚îÄ qc_assembly_env.yaml                  # Ambiente combinado QC
‚îÇ   ‚îú‚îÄ‚îÄ binning_env.yaml                      # Ambiente binning
‚îÇ   ‚îî‚îÄ‚îÄ tax_annot_env.yaml                    # Ambiente taxonom√≠a
‚îÇ
‚îú‚îÄ‚îÄ INSTALACI√ìN
‚îÇ   ‚îî‚îÄ‚îÄ INSTALACION_AMBIENTES.sh              # Instalador autom√°tico
‚îÇ
‚îî‚îÄ‚îÄ DOCUMENTACI√ìN
    ‚îú‚îÄ‚îÄ README.md                             # Este archivo
    ‚îú‚îÄ‚îÄ GUIA_RAPIDA.md                        # Gu√≠a de inicio r√°pido
    ‚îú‚îÄ‚îÄ RESUMEN_IMPLEMENTACION.md             # Documentaci√≥n t√©cnica
    ‚îî‚îÄ‚îÄ CHECKSUMS.md                          # Verificaci√≥n de integridad
```

---

## üöÄ Inicio R√°pido

### 1. Extraer el Paquete

```bash
tar -xzf pipeline_modular_completo.tar.gz
cd pipeline_modular_completo
```

### 2. Instalar Ambientes de Micromamba

**Opci√≥n A: Instalaci√≥n Autom√°tica (Recomendado)**

```bash
# Ejecutar script de instalaci√≥n autom√°tica
bash INSTALACION_AMBIENTES.sh
```

**Opci√≥n B: Instalaci√≥n Manual con YAMLs**

```bash
# Crear ambientes desde archivos YAML
micromamba env create -f 01_trimgalore.yaml
micromamba env create -f 02_host_removal.yaml
micromamba env create -f 03_megahit.yaml
micromamba env create -f 04_binning.yaml
micromamba env create -f 05_kraken2.yaml
micromamba env create -f 06_gtdbtk.yaml
micromamba env create -f 07_prokka.yaml
micromamba env create -f 08_rgi.yaml
micromamba env create -f 09_antismash.yaml
micromamba env create -f 10_analysis.yaml
```

### 3. Configurar Variables de Entorno

```bash
# Configurar GTDB-Tk (REQUERIDO para m√≥dulo 6)
export GTDBTK_DATA_PATH="/ruta/a/gtdbtk_db"

# Opcional: Agregar al .bashrc para persistencia
echo 'export GTDBTK_DATA_PATH="/ruta/a/gtdbtk_db"' >> ~/.bashrc
```

### 4. Editar Configuraci√≥n del Pipeline

Abre `metagenomics_pipeline.sh` y ajusta las siguientes variables (l√≠neas 36-52):

```bash
# Directorio base del proyecto
PROJECT_DIR="/files/shaday/4_cienegas"           # ‚Üê CAMBIAR

# Directorios de entrada/salida
INPUT_DIR="${PROJECT_DIR}/MergedFastq"           # ‚Üê CAMBIAR
OUTPUT_DIR="${PROJECT_DIR}/output"

# Bases de datos
BOWTIE2_INDEX="/ruta/a/bowtie2/index"            # ‚Üê CAMBIAR
KRAKEN2_GTDB="/ruta/a/k2_gtdb_r214"              # ‚Üê CAMBIAR
KRAKEN2_PLUSPFP="/ruta/a/k2_pluspfp"             # ‚Üê CAMBIAR (opcional)
KRAKEN2_EUPATH="/ruta/a/k2_eupathdb"             # ‚Üê CAMBIAR (opcional)
```

### 5. Ejecutar el Pipeline

```bash
# Ejecutar el pipeline interactivo
bash metagenomics_pipeline.sh
```

---

## üìö M√≥dulos del Pipeline

### M√≥dulo 1: QC & Trimming
- **Herramienta:** Trim Galore
- **Funci√≥n:** Control de calidad y recorte de adaptadores
- **Script individual:** `run_trimgalore.sh` (opcional)
- **Entrada:** Archivos FASTQ pareados (`*_1.fastq.gz`, `*_2.fastq.gz`)
- **Salida:** `output/trim/`

### M√≥dulo 2: Host Removal
- **Herramienta:** Bowtie2 + Samtools
- **Funci√≥n:** Remoci√≥n de reads del hospedador
- **Script individual:** `run_host_removal.sh` (opcional)
- **Entrada:** Reads trimados
- **Salida:** `output/host_removed/`

### M√≥dulo 3: Assembly
- **Herramienta:** MEGAHIT
- **Funci√≥n:** Ensamblaje de novo de metagenomas
- **Script individual:** `run_megahit.sh` (opcional)
- **Entrada:** Reads sin host
- **Salida:** `output/megahit_assemblies/`

### M√≥dulo 4: Binning
- **Herramienta:** MetaBAT2
- **Funci√≥n:** Agrupaci√≥n de contigs en bins (genomas)
- **Script individual:** `run_binning_fixed.sh` (usado por el pipeline)
- **Entrada:** Ensamblajes + reads
- **Salida:** `output/binning/`

### M√≥dulo 5: Taxonom√≠a de Reads
- **Herramienta:** Kraken2
- **Funci√≥n:** Clasificaci√≥n taxon√≥mica de reads
- **Script individual:** `run_kraken2.sh` (opcional)
- **Modos:** Simple (GTDB), Dual (GTDB+PlusPFP), Triple (GTDB+PlusPFP+EuPathDB)
- **Salida:** `output/kraken2_${MODE}/`

### M√≥dulo 6: Taxonom√≠a de Bins ‚ú® NUEVO
- **Herramienta:** GTDB-Tk
- **Funci√≥n:** Clasificaci√≥n taxon√≥mica de bins
- **Script individual:** `run_gtdbtk.sh` (opcional)
- **Entrada:** Bins de MetaBAT2
- **Salida:** `output/gtdbtk/`

### M√≥dulo 7: Anotaci√≥n ‚ú® NUEVO
- **Herramienta:** Prokka
- **Funci√≥n:** Anotaci√≥n funcional de genes
- **Script individual:** `run_prokka.sh` (opcional)
- **Entrada:** Bins
- **Salida:** `output/prokka/`

### M√≥dulo 8: Resistencia a Antibi√≥ticos ‚ú® NUEVO
- **Herramienta:** RGI (CARD)
- **Funci√≥n:** Detecci√≥n de genes de resistencia
- **Entrada:** Prote√≠nas de Prokka
- **Salida:** `output/rgi/`

### M√≥dulo 9: Metabolitos Secundarios ‚ú® NUEVO
- **Herramienta:** AntiSMASH
- **Funci√≥n:** Identificaci√≥n de clusters biosint√©ticos
- **Entrada:** Archivos GenBank de Prokka
- **Salida:** `output/antismash/`

### M√≥dulo 10: An√°lisis y Reportes
- **Herramientas:** Python (biom-format, pandas, matplotlib)
- **Funci√≥n:** Generaci√≥n de reportes HTML con gr√°ficos
- **Scripts:** `analisis_sin_metadatos.py`, `analisis_metagenomico_completo.py`
- **Entrada:** Reportes de Kraken2
- **Salida:** `output/analysis/`

---

## üõ†Ô∏è Requisitos del Sistema

### Hardware M√≠nimo
- **CPU:** 40+ cores
- **RAM:** 128 GB (256 GB recomendado para GTDB-Tk)
- **Disco:** 500 GB libres (1 TB recomendado)

### Software
- **Sistema Operativo:** Linux (Ubuntu 20.04+, CentOS 7+)
- **Micromamba/Conda:** Instalado y en PATH
- **Python:** 3.8+ (incluido en ambientes)
- **Bash:** 4.0+

### Bases de Datos Requeridas

| Base de Datos | M√≥dulo | Tama√±o | Descarga |
|---------------|--------|--------|----------|
| Bowtie2 Index (host) | 2 | Variable | Manual |
| Kraken2 GTDB | 5 | ~85 GB | https://benlangmead.github.io/aws-indexes/k2 |
| Kraken2 PlusPFP | 5 | ~50 GB | https://benlangmead.github.io/aws-indexes/k2 |
| Kraken2 EuPathDB | 5 | ~15 GB | https://benlangmead.github.io/aws-indexes/k2 |
| GTDB-Tk | 6 | ~85 GB | https://data.gtdb.ecogenomic.org/ |
| CARD | 8 | ~100 MB | https://card.mcmaster.ca/download |
| AntiSMASH | 9 | ~5 GB | Descarga autom√°tica |

---

## üìñ Documentaci√≥n Adicional

- **`GUIA_RAPIDA.md`**: Gu√≠a paso a paso con casos de uso comunes
- **`RESUMEN_IMPLEMENTACION.md`**: Documentaci√≥n t√©cnica detallada de los m√≥dulos 6-9
- **`INSTALACION_AMBIENTES.sh`**: Script automatizado de instalaci√≥n
- **`CHECKSUMS.md`**: Verificaci√≥n de integridad del paquete

---

## üîß Uso de Scripts Individuales

Aunque el pipeline principal (`metagenomics_pipeline.sh`) incluye toda la funcionalidad, puedes ejecutar m√≥dulos individuales:

```bash
# Ejemplo: Ejecutar solo el m√≥dulo de binning
bash run_binning_fixed.sh

# Ejemplo: Ejecutar solo GTDB-Tk
bash run_gtdbtk.sh

# Ejemplo: Ejecutar solo Prokka
bash run_prokka.sh
```

**Nota:** Los scripts individuales pueden requerir ajustes de rutas seg√∫n tu configuraci√≥n.

---

## üêõ Soluci√≥n de Problemas

### Error: "micromamba no encontrado"

```bash
# Verificar instalaci√≥n
which micromamba

# Si no est√° instalado, descargar:
curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
sudo mv bin/micromamba /usr/local/bin/
```

### Error: "GTDBTK_DATA_PATH no configurada"

```bash
# Descargar base de datos GTDB
wget https://data.gtdb.ecogenomic.org/releases/latest/auxillary_files/gtdbtk_data.tar.gz
tar -xzf gtdbtk_data.tar.gz

# Configurar variable
export GTDBTK_DATA_PATH=/ruta/a/gtdbtk_data
```

### Error: "No se encontr√≥ el directorio de binning"

Aseg√∫rate de ejecutar los m√≥dulos en orden secuencial. El m√≥dulo 6 requiere que el m√≥dulo 4 (Binning) se haya completado.

---

## üìä Tiempos de Ejecuci√≥n Estimados

**Hardware:** 60 cores, 256 GB RAM

| M√≥dulo | 2 muestras | 10 muestras |
|--------|------------|-------------|
| 1-5    | 8-12 horas | 40-60 horas |
| 6      | 4-8 horas  | 20-40 horas |
| 7      | 2-4 horas  | 10-20 horas |
| 8      | 1-2 horas  | 5-10 horas  |
| 9      | 4-8 horas  | 20-40 horas |
| 10     | 10 min     | 30 min      |
| **Total** | **20-35 horas** | **95-170 horas** |

---

## ü§ù Contribuciones

Este pipeline fue desarrollado por:
- **Shaday Guerrero** (Investigadora principal)
- **Manus AI** (Implementaci√≥n y documentaci√≥n)

---

## üìù Licencia

Este software es de uso acad√©mico. Para uso comercial, contactar a los autores.

---

## üìß Contacto

Para reportar problemas o solicitar nuevas funcionalidades, consulta la documentaci√≥n o contacta al equipo de desarrollo.

---

**Versi√≥n:** 1.0  
**Fecha:** 29 de noviembre de 2025  
**Estado:** ‚úÖ Producci√≥n (10 m√≥dulos completos)  
**Archivos totales:** 32 (scripts, YAMLs, documentaci√≥n)
